\section{\textbf{Introduction}}
    In many real-world cooperative multiagent reinforcement learning (MARL) tasks, agents can train together but must execute independently due to communication constraints. The Centralized Training and Decentralized Execution (CTDE) framework is popular in this context, focusing on training agents as a team but executing individually. This approach leverages the benefits of centralized training, such as improved coordination and learning efficiency, while maintaining the flexibility and scalability of decentralized execution. The introduction section highlights the importance of balancing these aspects to achieve effective and practical MARL solutions. It also emphasizes the challenges and potential strategies for optimizing agent performance in such settings.
